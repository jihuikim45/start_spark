{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6887a77a-443d-4f38-a064-70e8a0305ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Spark 세션 재생성\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"accident-severity-prediction\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42498b26-e87f-4978-9b67-d7f3bb0dc984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. accident_df 다시 로드\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "a_data_path = os.path.join(cwd, 'learning_spark_data', 'accident' , 'Accident_Information.csv')\n",
    "a_file_path = f\"file:///{a_data_path.replace(os.sep, '/')}\"\n",
    "accident_df = spark.read.csv(a_file_path, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bda6682-0644-4afa-a4d3-2c6c95606ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Slight', 'Serious', 'Fatal']\n",
      "+-----------------+-----+\n",
      "|Accident_Severity|label|\n",
      "+-----------------+-----+\n",
      "|          Serious|  1.0|\n",
      "|           Slight|  0.0|\n",
      "|           Slight|  0.0|\n",
      "|           Slight|  0.0|\n",
      "|           Slight|  0.0|\n",
      "|           Slight|  0.0|\n",
      "|           Slight|  0.0|\n",
      "|           Slight|  0.0|\n",
      "|           Slight|  0.0|\n",
      "|           Slight|  0.0|\n",
      "+-----------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 불러오기\n",
    "accident_df = spark.read.csv(a_file_path, inferSchema=True, header=True)\n",
    "\n",
    "# StringIndexer로 fit 및 transform\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "severity_indexer = StringIndexer(inputCol=\"Accident_Severity\", outputCol=\"label\")\n",
    "severity_indexer_model = severity_indexer.fit(accident_df)\n",
    "\n",
    "print(severity_indexer_model.labels)  # 레이블 순서 확인용\n",
    "\n",
    "accident_df = severity_indexer_model.transform(accident_df)\n",
    "accident_df.select(\"Accident_Severity\", \"label\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c403022-a175-44cd-b11a-acd1af9bb47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Age_Band_of_Driver: string (nullable = true)\n",
      " |-- Age_of_Vehicle: string (nullable = true)\n",
      " |-- Driver_Home_Area_Type: string (nullable = true)\n",
      " |-- Driver_IMD_Decile: string (nullable = true)\n",
      " |-- Engine_Capacity_.CC.: string (nullable = true)\n",
      " |-- Hit_Object_in_Carriageway: string (nullable = true)\n",
      " |-- Hit_Object_off_Carriageway: string (nullable = true)\n",
      " |-- Journey_Purpose_of_Driver: string (nullable = true)\n",
      " |-- Junction_Location: string (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- Propulsion_Code: string (nullable = true)\n",
      " |-- Sex_of_Driver: string (nullable = true)\n",
      " |-- Skidding_and_Overturning: string (nullable = true)\n",
      " |-- Towing_and_Articulation: string (nullable = true)\n",
      " |-- Vehicle_Leaving_Carriageway: string (nullable = true)\n",
      " |-- Vehicle_Location.Restricted_Lane: string (nullable = true)\n",
      " |-- Vehicle_Manoeuvre: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Vehicle_Type: string (nullable = true)\n",
      " |-- Was_Vehicle_Left_Hand_Drive: string (nullable = true)\n",
      " |-- X1st_Point_of_Impact: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vehicle 불러오기\n",
    "v_data_path = os.path.join(cwd, 'learning_spark_data', 'accident' , 'Vehicle_Information.csv')\n",
    "v_file_path = f\"file:///{v_data_path.replace(os.sep, '/')}\"\n",
    "\n",
    "# 2. CSV 파일 읽기\n",
    "vehicle_df = spark.read.csv(v_file_path, inferSchema=True, header=True)\n",
    "\n",
    "# 3. 스키마 확인 (선택)\n",
    "vehicle_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b363d80-bcc6-4205-a157-e42862fbc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_df rename \n",
    "vehicle_df = vehicle_df.withColumnRenamed(\"Engine_Capacity_.CC.\", \"Engine_Capacity\")\n",
    "\n",
    "# accident_df와 vehicle_df 조인 하기\n",
    "df = accident_df.join(vehicle_df, on=\"Accident_Index\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd7e6b8-0257-4963-b97b-8a10cd406f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"Age_Band_of_Driver\",\n",
    "    when(col(\"Age_Band_of_Driver\") == \"Data missing or out of range\", \"Unknown_Age\")\n",
    "    .otherwise(col(\"Age_Band_of_Driver\"))\n",
    ").withColumn(\n",
    "    \"Sex_of_Driver\",\n",
    "    when(col(\"Sex_of_Driver\").isin(\"Not known\", \"Data missing or out of range\"), \"Unknown_Sex\")\n",
    "    .otherwise(col(\"Sex_of_Driver\"))\n",
    ").withColumn(\n",
    "    \"Vehicle_Type\",\n",
    "    when(col(\"Vehicle_Type\").rlike(\"(?i)(unknown|other|Data missing)\"), \"Other_Vehicle\")\n",
    "    .otherwise(col(\"Vehicle_Type\"))\n",
    ").withColumn(\n",
    "    \"Journey_Purpose_of_Driver\",\n",
    "    when(col(\"Journey_Purpose_of_Driver\").isin(\"Not known\", \"Other\", \"Other/Not known (2005-10)\", \"Data missing or out of range\"), \"Unknown_Purpose\")\n",
    "    .otherwise(col(\"Journey_Purpose_of_Driver\"))\n",
    ").withColumn(\n",
    "    \"Road_Type\",\n",
    "    when(col(\"Road_Type\").isin(\"Unknown\", \"Data missing or out of range\"), \"Unknown_Road\")\n",
    "    .otherwise(col(\"Road_Type\"))\n",
    ").withColumn(\n",
    "    \"Light_Conditions\",\n",
    "    when(col(\"Light_Conditions\").isin(\"Darkness - lighting unknown\", \"Data missing or out of range\"), \"Unknown_Light\")\n",
    "    .otherwise(col(\"Light_Conditions\"))\n",
    ").withColumn(\n",
    "    \"Urban_or_Rural_Area\",\n",
    "    when(col(\"Urban_or_Rural_Area\") == \"Unallocated\", \"Unknown_Area\")\n",
    "    .otherwise(col(\"Urban_or_Rural_Area\"))\n",
    ").withColumn(\n",
    "    \"Speed_limit\",\n",
    "    when(col(\"Speed_limit\").cast(\"string\").isin(\"NA\", \"0\", \"10\", \"15\"), \"Unknown_Speed\")\n",
    "    .otherwise(col(\"Speed_limit\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34806856-33a9-4435-96f6-738bf049fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "categorical_cols = [\n",
    "    \"Age_Band_of_Driver\",\n",
    "    \"Sex_of_Driver\",\n",
    "    \"Vehicle_Type\",\n",
    "    \"Journey_Purpose_of_Driver\",\n",
    "    \"Weather_Conditions\",\n",
    "    \"Road_Type\",\n",
    "    \"Day_of_Week\",\n",
    "    \"Light_Conditions\",\n",
    "    \"Urban_or_Rural_Area\",\n",
    "    \"Speed_limit\"\n",
    "]\n",
    "\n",
    "# 인덱서 + 인코더 정의\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c + \"_idx\", handleInvalid=\"keep\") for c in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=c + \"_idx\", outputCol=c + \"_vec\") for c in categorical_cols]\n",
    "\n",
    "# 파이프라인 구성\n",
    "pipeline = Pipeline(stages=indexers + encoders)\n",
    "df_encoded = pipeline.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a1fea8-435c-49d3-8d20-a0fa664b9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engine_Capacity 처리\n",
    "from pyspark.sql.functions import mean\n",
    "mean_val = df_encoded.select(mean(\"Engine_Capacity\")).first()[0]\n",
    "df_encoded = df_encoded.withColumn(\"Engine_Capacity\", col(\"Engine_Capacity\").cast(\"double\"))\n",
    "df_encoded = df_encoded.fillna({\"Engine_Capacity\": mean_val})\n",
    "\n",
    "# VectorAssembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "feature_cols = [c + \"_vec\" for c in categorical_cols] + [\"Engine_Capacity\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "final_df = assembler.transform(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8233ee88-c641-495b-a034-57d3608c167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# label_binary 생성\n",
    "binary_df = final_df.withColumn(\n",
    "    \"label_binary\",\n",
    "    when(col(\"label\") == 0.0, 0.0).otherwise(1.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f54faa0d-250c-4e65-9bce-a909459ffa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|label_binary|  count|\n",
      "+------------+-------+\n",
      "|         0.0|1765650|\n",
      "|         1.0| 292758|\n",
      "+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_df.groupBy(\"label_binary\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676fd1c0-8287-4b39-8e1f-59c654303f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------------------------------------+\n",
      "|label_binary|prediction|probability                             |\n",
      "+------------+----------+----------------------------------------+\n",
      "|0.0         |0.0       |[0.878541105892094,0.121458894107906]   |\n",
      "|0.0         |0.0       |[0.748624635479233,0.25137536452076703] |\n",
      "|0.0         |0.0       |[0.862015857256882,0.137984142743118]   |\n",
      "|0.0         |0.0       |[0.8906087431469926,0.10939125685300743]|\n",
      "|0.0         |0.0       |[0.786721726665338,0.21327827333466198] |\n",
      "+------------+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 모델 학습\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr_bin = LogisticRegression(featuresCol=\"features\", labelCol=\"label_binary\", maxIter=10)\n",
    "lr_bin_model = lr_bin.fit(binary_df)\n",
    "\n",
    "# 예측\n",
    "pred_bin = lr_bin_model.transform(binary_df)\n",
    "pred_bin.select(\"label_binary\", \"prediction\", \"probability\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286909a6-49b1-498a-9e29-26c052883ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8587\n",
      "F1 Score: 0.7986\n",
      "정밀도: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o1522.evaluate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluator_f1\u001b[38;5;241m.\u001b[39mevaluate(pred_bin)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m정밀도: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluator_pre\u001b[38;5;241m.\u001b[39mevaluate(pred_bin)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m재현률: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mevaluator_rec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_bin\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluator_auc\u001b[38;5;241m.\u001b[39mevaluate(pred_bin)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/evaluation.py:111\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_evaluate(dataset)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/evaluation.py:148\u001b[0m, in \u001b[0;36mJavaEvaluator._evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o1522.evaluate"
     ]
    }
   ],
   "source": [
    "# Accuracy, F1, AUC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"label_binary\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label_binary\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label_binary\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_pre = MulticlassClassificationEvaluator(labelCol=\"label_binary\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_rec = MulticlassClassificationEvaluator(labelCol=\"label_binary\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "print(f\"정확도: {evaluator_acc.evaluate(pred_bin):.4f}\")\n",
    "print(f\"F1 Score: {evaluator_f1.evaluate(pred_bin):.4f}\")\n",
    "print(f\"정밀도: {evaluator_pre.evaluate(pred_bin):.4f}\")\n",
    "print(f\"재현률: {evaluator_rec.evaluate(pred_bin):.4f}\")\n",
    "print(f\"AUC: {evaluator_auc.evaluate(pred_bin):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106df833-5143-4def-9025-ebcaadc371e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동행렬\n",
    "pred_bin.groupBy(\"label_binary\", \"prediction\").count().orderBy(\"label_binary\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d4a63-3cdc-43bb-b28d-25aa37740f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9079e-1fb7-41b7-80a4-2c08df7a4aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0b794-2625-4703-8597-6cedcf8cd0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754955c2-f688-436a-aa75-34adae04a4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799353a6-5a6b-4035-8bed-e534ae7e42fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe0136-4ff1-4d01-ab29-7bdc77388c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b4edb-1db1-4912-b069-8dad94e796ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ad1a6-5ef9-4584-b6e1-48b8cbb0fd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d62793-4ffd-4b48-88a0-09f17bc42046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86823d-a1ba-4503-a12d-18ca9f32f227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568cabe-5e94-4bd8-91c5-13880294d6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9a86ae-93e1-426c-8e20-bf68f96917dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3a56a-6fdd-42b0-8538-de9dcb1f2941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61f2cf-9c64-4e05-bcbd-810135f12b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdd9bd-d23e-48c3-ae61-98f1d2be9a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ea5d3-45d5-4a84-95c4-6d9490d63db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a4533-8e69-4c1d-8073-07ef7863a2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbab95-0ccb-460e-b456-c65e4e262b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10189fde-4771-46dc-9180-747ba8916292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691fc745-7c59-40ca-8232-6f2a46c1c4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950c3d0-fe34-46c3-a307-59d2fbc619a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04621b-a306-494b-88b7-df680255ea21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af728f-f987-4d8a-b4aa-7892847de99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000281e3-fcb4-4338-8c55-0603c3b210bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802dd988-af76-48d0-8cd1-b5f2665c4f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac56ff-82cc-4386-bea6-2b891afcbafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e31514-0831-4252-b556-0d531ab5b62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72664012-1f06-4f3c-b71b-0055e3a266ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d96f5-d779-41f8-8063-20cf39d87951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad77976-fe0a-4a74-91e9-0574e91987e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a2121-459c-4e64-85c5-e34236e48e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79932f-e947-462e-ac33-10762c5c5711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c4f56-905b-41aa-bec8-df08c23352f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
